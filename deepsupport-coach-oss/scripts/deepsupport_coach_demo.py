# -*- coding: utf-8 -*-
import os
import json
import argparse
import socket
import uuid
import datetime
import threading
from typing import Any, Dict, List, Optional

import re
import torch
import gradio as gr


# ------------------------------
# Macaron UI skin (pure CSS)
# ------------------------------
MACARON_CSS = r'''
:root{
  --ds-bg1:#ffd3e8;
  --ds-bg2:#d7efff;
  --ds-bg3:#d9ffe9;
  --ds-bg4:#fff3c8;
  --ds-bg5:#e9ddff;

  --ds-ink:#2f2f46;
  --ds-ink-soft:rgba(47,47,70,.72);

  --ds-card:rgba(255,255,255,.80);
  --ds-card-border:rgba(255,255,255,.58);
  --ds-shadow:0 18px 55px rgba(47,47,70,.10);

  --ds-accent:#ff6fb1;
  --ds-accent2:#ffb36b;
  --ds-accent3:#fff07a;
  --ds-accent4:#7dffb0;
  --ds-accent5:#6de8ff;
  --ds-accent6:#7ba9ff;
  --ds-accent7:#c49bff;

  --ds-radius:26px;
}

body, .gradio-container{
  background:
    radial-gradient(1200px 820px at 6% 14%, rgba(255,111,177,.60), transparent 58%),
    radial-gradient(1050px 760px at 92% 18%, rgba(109,232,255,.58), transparent 58%),
    radial-gradient(1150px 860px at 82% 92%, rgba(125,255,176,.55), transparent 60%),
    radial-gradient(980px 760px at 18% 88%, rgba(196,155,255,.45), transparent 60%),
    radial-gradient(980px 760px at 52% 8%, rgba(255,240,122,.30), transparent 62%),
    linear-gradient(135deg,var(--ds-bg1),var(--ds-bg2),var(--ds-bg3)) !important;
}

.gradio-container{
  min-height: 100vh;
  padding-bottom: 24px;
}

.gradio-container::before,
.gradio-container::after{
  content:"";
  position: fixed;
  inset: -20vh -20vw;
  pointer-events:none;
  z-index:0;
  background:
    radial-gradient(circle at 10% 18%, rgba(255,111,177,.34) 0 18%, transparent 19% 100%),
    radial-gradient(circle at 88% 22%, rgba(109,232,255,.32) 0 16%, transparent 17% 100%),
    radial-gradient(circle at 78% 84%, rgba(125,255,176,.28) 0 20%, transparent 21% 100%),
    radial-gradient(circle at 18% 86%, rgba(196,155,255,.26) 0 18%, transparent 19% 100%),
    radial-gradient(circle at 52% 10%, rgba(255,240,122,.18) 0 16%, transparent 17% 100%);
  filter: saturate(1.15);
  animation: dsFloat 18s ease-in-out infinite alternate;
}
.gradio-container::after{
  animation-duration: 24s;
  opacity: .85;
}

@keyframes dsFloat{
  0%{ transform: translate3d(0,0,0) scale(1); }
  100%{ transform: translate3d(1.8vw,-1.2vh,0) scale(1.02); }
}

#ds_header{
  position: relative;
  z-index: 1;
  max-width: 1320px;
  margin: 18px auto 10px auto;
  padding: 0 14px;
}

.ds-title{
  font-size: 46px;
  line-height: 1.05;
  font-weight: 900;
  letter-spacing: .3px;
  margin: 4px 0 10px 0;
  color: var(--ds-ink);
}
.ds-title .grad{ color: var(--ds-accent); }
@supports ((-webkit-background-clip: text) or (background-clip: text)) {
  .ds-title .grad{
    background: linear-gradient(90deg,var(--ds-accent),var(--ds-accent2),var(--ds-accent3),var(--ds-accent4),var(--ds-accent5),var(--ds-accent6),var(--ds-accent7));
    -webkit-background-clip: text;
    background-clip: text;
    color: transparent;
  }
}
.ds-sub{
  margin-top: -6px;
  font-size: 14px;
  color: var(--ds-ink-soft);
}

.ds-shell{
  position: relative;
  z-index: 1;
  max-width: 1320px;
  margin: 0 auto;
  padding: 10px 14px 0 14px;
  align-items: stretch;
}

.ds-card{
  background: var(--ds-card);
  border: 1px solid var(--ds-card-border);
  border-radius: var(--ds-radius);
  box-shadow: var(--ds-shadow);
  backdrop-filter: blur(10px);
  -webkit-backdrop-filter: blur(10px);
  padding: 14px 14px 6px 14px;
  min-height: 640px;
  display: flex;
  flex-direction: column;
}

.ds-flex-spacer{flex:1;}

#ds_btn, #ds_btn_new{margin-top: 8px !important; margin-bottom: 0 !important;}
#ds_btn button, #ds_btn_new button{margin-bottom: 0 !important;}
#ds_btn .wrap, #ds_btn_new .wrap{margin-bottom:0 !important;}

#ds_user textarea{
  border-radius: 18px !important;
  border: 1px solid rgba(47,47,70,.12) !important;
  background: rgba(255,255,255,.85) !important;
  box-shadow: 0 10px 22px rgba(47,47,70,.06);
  font-size: 16px !important;
}

label, .wrap .label{
  color: var(--ds-ink) !important;
  font-weight: 700 !important;
}

.gradio-container .prose, .gradio-container .md{
  color: var(--ds-ink) !important;
}

.ds-tip{
  color: var(--ds-ink-soft) !important;
  font-size: 13px !important;
}

#ds_btn button, #ds_btn_new button{
  width: 100%;
  border-radius: 999px !important;
  border: none !important;
  background: linear-gradient(90deg,var(--ds-accent),var(--ds-accent2)) !important;
  box-shadow: 0 14px 34px rgba(255,143,184,.24);
  font-weight: 900 !important;
  letter-spacing: .4px;
  transition: transform .08s ease, filter .08s ease;
}
#ds_btn button:hover, #ds_btn_new button:hover{
  transform: translateY(-1px);
  filter: brightness(1.02);
}
#ds_btn button:active, #ds_btn_new button:active{
  transform: translateY(0px) scale(.99);
}

input[type="checkbox"]{ accent-color: var(--ds-accent) !important; }
.gradio-container input[type="range"]{ accent-color: var(--ds-accent2) !important; }

.ds-out-title{ margin-top: 2px; }
#ds_out{ padding: 6px 8px; }
#ds_out .prose{ font-size: 15px; line-height: 1.5; }
#ds_out h1, #ds_out h2, #ds_out h3{ color: #2b2f55 !important; }
#ds_out ul li::marker{ color: var(--ds-accent2); }
'''

HEADER_HTML = r'''
<div id="ds_header">
  <div class="ds-title">âœ¨ <span class="grad">DeepSupport Coach ğŸ§‘â€ğŸ«</span> ğŸ«§</div>
  <div class="ds-sub">å¸®ä½ æŠŠé—®é¢˜æ‹†å¼€ã€æ¨æ¼”ã€ç»™ä½ ä¸‹ä¸€æ­¥ âœ…</div>
</div>
'''


# -------------------- Report spec (prompt structure) --------------------
REPORT_SPEC = r"""
ä½ æ˜¯ DeepSupport-Coachï¼Œä¸€ä¸ªç»“æ„åŒ–æ”¯æŒå·¥å…·ï¼ˆä¸æ˜¯å¿ƒç†æ²»ç–—/åŒ»ç–—å»ºè®®ï¼‰ã€‚
ä½ çš„ç›®æ ‡ï¼šç”¨**çŸ­ã€æ¸…æ™°ã€æœ‰è¾¹ç•Œ**çš„æ–¹å¼ï¼Œå¸®åŠ©ç”¨æˆ·å¿«é€Ÿè¯†åˆ«ç—›ç‚¹ã€æ‹†åˆ†å˜é‡ã€ç»™å‡ºä¸¤æ¡è·¯çº¿ï¼Œå¹¶æå‰å›ç­”å¯èƒ½é—®é¢˜ã€‚
ä¸è¦è¾“å‡ºè¶…é•¿æ¨æ¼”ï¼›ä¸è¦é•¿ç¯‡é“ç†ï¼›ä¸è¦é¸¡æ±¤ï¼›ä¸è¦å¤¸ç”¨æˆ·ï¼›ä¸è¦æ¨¡æ¿åŒ–â€œæˆ‘ç†è§£ä½ å¾ˆéš¾â€ã€‚

è¾“å‡ºæ ¼å¼ï¼šä¸¥æ ¼æŒ‰ä»¥ä¸‹ 8 æ®µï¼Œç”¨ä¸­æ–‡ã€Markdownï¼š
0) ä½ ç°åœ¨çš„å¤„å¢ƒï¼ˆ1-2å¥å¤è¿°ï¼Œä¸è¦æ‰©å†™ï¼‰
1) ç—›ç‚¹ä¸€å¥è¯ï¼ˆ<=25å­—ï¼‰
2) å…³é”®å˜é‡æ¸…å•
   - å·²çŸ¥ï¼š2-4æ¡ï¼ˆæ¯æ¡<=14å­—ï¼‰
   - å¾…ç¡®è®¤ï¼š2-4æ¡ï¼ˆæ¯æ¡<=14å­—ï¼Œå†™æˆé—®é¢˜ï¼‰
3) æ¨æ¼”åˆ†å‰ï¼ˆ2æ¡ï¼Œæ¯æ¡<=60å­—ï¼Œå†™â€œå¦‚æœâ€¦é‚£ä¹ˆâ€¦â€ï¼‰
4) ä¸¤æ¡è·¯çº¿
   - Aï¼šæ›´ç¨³/æ›´ä¿å®ˆï¼ˆ1å¥<=70å­—ï¼‰
   - Bï¼šæ›´ç›´æ¥/æ›´è¿›æ”»ï¼ˆ1å¥<=70å­—ï¼‰
5) ä»Šå¤©å°±èƒ½åšçš„ 3 æ­¥ï¼ˆ3æ¡ï¼Œæ¯æ¡<=20å­—ï¼‰
6) çº¢æ——ï¼ˆ<=60å­—ï¼›å¦‚æœæ²¡æœ‰æ˜æ˜¾é£é™©ï¼Œå†™â€œæš‚æ— æ˜æ˜¾çº¢æ——ï¼Œä½†è‹¥æŒç»­å½±å“ç”Ÿæ´»å»ºè®®æ±‚åŠ©ä¸“ä¸šäººå£«â€ã€‚ï¼‰
7) ä½ æ¥ä¸‹æ¥å¯èƒ½ä¼šé—®ï¼ˆ4-6ä¸ª Q&Aï¼›Q<=18å­—ï¼›A<=45å­—ï¼›ä¸ç©ºè¯ï¼Œå°½é‡â€œå¯æ“ä½œ/å¯æ£€éªŒâ€ï¼‰

é¢å¤–è§„åˆ™ï¼š
- å¦‚æœç”¨æˆ·æè¿°â€œåŸå› ä¸æ˜/è¯´ä¸æ¸…â€ï¼Œç¬¬2æ®µâ€œå¾…ç¡®è®¤â€å¿…é¡»åŒ…å«â€œæœ€è¿‘æ˜¯å¦æœ‰å‹åŠ›äº‹ä»¶/ä½œæ¯å˜åŒ–/èº«ä½“ä¸é€‚â€ä¹‹ä¸€ã€‚
- ä½ å°†çœ‹åˆ°â€œé£æ ¼ç¤ºä¾‹/ICL ç¤ºä¾‹â€ï¼Œå®ƒä»¬ä»…ç”¨äºå­¦ä¹ è¯­æ°”ã€èŠ‚å¥ä¸æ’ç‰ˆï¼›
  **ä¸å¾—é€å­—å¤åˆ¶**ä»»ä½•å¥å­ï¼Œä¸”ä¸å¾—æŠŠç¤ºä¾‹å†…å®¹å½“ä½œäº‹å®å¸¦å…¥å›ç­”ã€‚
""".strip()

DEFAULT_TEMP = 0.10
DEFAULT_MAX_NEW_TOKENS = 420


# -------------------- Helpers --------------------
def decorate_output(text: str) -> str:
    """Add tasteful emojis to numbered headers; avoid inventing content."""
    if not isinstance(text, str):
        return text
    emoji_map = {"0": "ğŸ§­", "1": "ğŸ¯", "2": "ğŸ§©", "3": "ğŸ”€", "4": "ğŸ›£ï¸", "5": "âœ…", "6": "ğŸš©", "7": "â“"}
    lines = text.splitlines()
    out_lines = []
    for ln in lines:
        m = re.match(r"^\s*(\d+)\.\s*(.*)$", ln)
        if m and m.group(1) in emoji_map:
            num = m.group(1)
            rest = m.group(2)
            out_lines.append(f"{emoji_map[num]} {num}. {rest}".rstrip())
            continue
        ln = re.sub(r"^\s*å·²çŸ¥\s*:", "âœ… å·²çŸ¥:", ln)
        ln = re.sub(r"^\s*å¾…ç¡®è®¤\s*:", "ğŸ•µï¸ å¾…ç¡®è®¤:", ln)
        out_lines.append(ln)
    return "\n".join(out_lines)


def _is_port_free(port: int, host: str = "0.0.0.0") -> bool:
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        try:
            s.bind((host, port))
            return True
        except OSError:
            return False


def _pick_free_port(preferred: int, host: str, span: int = 50) -> int:
    if preferred == 0:
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            s.bind((host, 0))
            return int(s.getsockname()[1])
    if _is_port_free(preferred, host=host):
        return preferred
    for p in range(preferred + 1, preferred + 1 + span):
        if _is_port_free(p, host=host):
            return p
    raise RuntimeError(f"No free port found in range [{preferred}, {preferred + span}]. Try --port 0.")


def _now_iso() -> str:
    return datetime.datetime.utcnow().replace(microsecond=0).isoformat() + "Z"


def _truncate(s: str, max_chars: int) -> str:
    s = (s or "").strip()
    if len(s) <= max_chars:
        return s
    return s[: max_chars - 1].rstrip() + "â€¦"


def _basic_safety_sanitize(s: str, max_chars: int = 900) -> str:
    """Light sanitizer for OSS defaults. Not a full PII scrubber."""
    s = _truncate(s, max_chars=max_chars)
    s = re.sub(r"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}", "[email]", s)
    s = re.sub(r"\b(\+?\d[\d\s-]{7,}\d)\b", "[phone]", s)
    return s


# -------------------- ICL (safe) --------------------
SYNTHETIC_ICL: List[Dict[str, str]] = [
    {
        "user": "æˆ‘ä»Šå¤©è¢«é¢†å¯¼å½“ä¼—å¦å®šäº†ï¼Œè„‘å­ä¸€ç›´è½¬ï¼Œæ„Ÿè§‰å¾ˆéš¾å—ã€‚",
        "assistant": """0) ä½ ç°åœ¨çš„å¤„å¢ƒï¼šä½ åœ¨å…¬å¼€åœºåˆè¢«å¦å®šï¼Œæƒ…ç»ªå—æŒ«ï¼Œåå¤å›æƒ³ç»†èŠ‚ã€‚
1) ç—›ç‚¹ä¸€å¥è¯ï¼šå¦å®šæ„Ÿ+ååˆåœä¸ä¸‹æ¥
2) å…³é”®å˜é‡æ¸…å•
- å·²çŸ¥ï¼šå½“ä¼—è¢«å¦å®šï¼›æƒ…ç»ªå¾ˆéš¾å—ï¼›åå¤å›æƒ³
- å¾…ç¡®è®¤ï¼šå¯¹æ–¹å…·ä½“å¦å®šä»€ä¹ˆï¼Ÿä½ æœ€æ€•çš„åæœï¼Ÿæœ‰å¯è¡¥æ•‘åŠ¨ä½œå—ï¼Ÿ
3) æ¨æ¼”åˆ†å‰
- å¦‚æœåªæ˜¯è¡¨è¾¾æ–¹å¼ç²—ç³™ï¼Œé‚£ä¹ˆâ€¦æŠŠåé¦ˆè½¬æˆå¯æ‰§è¡Œæ¸…å•
- å¦‚æœæ¶‰åŠç«‹åœº/ç»©æ•ˆï¼Œé‚£ä¹ˆâ€¦å‡†å¤‡è¯æ®ä¸æ²Ÿé€šèŠ‚å¥
4) ä¸¤æ¡è·¯çº¿
- Aï¼šå…ˆç¨³ä½æƒ…ç»ªï¼Œå†æ•´ç†1é¡µå¤ç›˜ä¸æ”¹åŠ¨ç‚¹
- Bï¼šå°½å¿«çº¦10åˆ†é’Ÿå¯¹é½æ ‡å‡†ï¼Œç¡®è®¤â€œåˆ°åº•è¦æˆ‘æ€ä¹ˆæ”¹â€
5) ä»Šå¤©å°±èƒ½åšçš„ 3 æ­¥
- å†™ä¸‹3ä¸ªè¢«å¦å®šç‚¹
- æŠŠæ¯ç‚¹æ”¹æˆ1ä¸ªåŠ¨ä½œ
- é€‰1ä½åŒäº‹å¤æ ¸
6) çº¢æ——ï¼šæš‚æ— æ˜æ˜¾çº¢æ——ï¼Œä½†è‹¥æŒç»­å½±å“ç”Ÿæ´»å»ºè®®æ±‚åŠ©ä¸“ä¸šäººå£«ã€‚
7) ä½ æ¥ä¸‹æ¥å¯èƒ½ä¼šé—®
Qï¼šéœ€è¦ç«‹åˆ»è§£é‡Šå—ï¼ŸAï¼šå…ˆç¡®è®¤å¯¹æ–¹è¦çš„â€œæ ‡å‡†â€ï¼Œå†è§£é‡Šæ›´æœ‰æ•ˆã€‚
Qï¼šä¸€ç›´æƒ³èµ·æ€ä¹ˆåŠï¼ŸAï¼šç»™ååˆä¸€ä¸ªâ€œç»“æŸå¥â€ï¼Œç„¶åå»åšä¸€ä¸ªå°åŠ¨ä½œã€‚""",
    },
    {
        "user": "æˆ‘æœ€è¿‘æ€»æ˜¯è‡ªæˆ‘å¦å®šï¼Œæ˜æ˜æ²¡å‘ç”Ÿå¤§äº‹ï¼Œä½†å°±æ˜¯å¾ˆç´¯ã€‚",
        "assistant": """0) ä½ ç°åœ¨çš„å¤„å¢ƒï¼šä½ é•¿æœŸå¤„åœ¨è‡ªæˆ‘å¦å®šé‡Œï¼Œæ²¡æœ‰æ˜ç¡®è§¦å‘ç‚¹ï¼Œä½†æ¶ˆè€—å¾ˆå¤§ã€‚
1) ç—›ç‚¹ä¸€å¥è¯ï¼šæ…¢æ€§å†…è€—å¯¼è‡´ç–²æƒ«
2) å…³é”®å˜é‡æ¸…å•
- å·²çŸ¥ï¼šç»å¸¸å¦å®šè‡ªå·±ï¼›æ²¡æœ‰æ˜æ˜¾äº‹ä»¶ï¼›æŒç»­ç–²æƒ«
- å¾…ç¡®è®¤ï¼šæœ€è¿‘ä½œæ¯å˜åŒ–ï¼Ÿå‹åŠ›äº‹ä»¶ï¼Ÿèº«ä½“ä¸é€‚ï¼Ÿä½ æœ€å¸¸å¦å®šå“ªä¸€ç±»äº‹æƒ…ï¼Ÿ
3) æ¨æ¼”åˆ†å‰
- å¦‚æœæ˜¯ä½œæ¯/å‹åŠ›ç´¯ç§¯ï¼Œé‚£ä¹ˆâ€¦å…ˆåšèŠ‚å¾‹ä¿®å¤ä¸èƒ½é‡æ¢å¤
- å¦‚æœæ˜¯æ ‡å‡†è¿‡é«˜/è¯„ä»·ä½“ç³»å¤±è¡¡ï¼Œé‚£ä¹ˆâ€¦é‡å»ºâ€œåˆæ ¼çº¿â€
4) ä¸¤æ¡è·¯çº¿
- Aï¼šå…ˆæ¢å¤ä½“åŠ›ä¸èŠ‚å¾‹ï¼Œå†è°ˆæå‡
- Bï¼šæŠŠâ€œè‡ªæˆ‘è¯„åˆ¤â€æ”¹æˆâ€œå¯éªŒè¯ä»»åŠ¡â€
5) ä»Šå¤©å°±èƒ½åšçš„ 3 æ­¥
- å†™ä¸‹3æ¡è‡ªæˆ‘æ‰¹è¯„
- ä¸ºæ¯æ¡æ‰¾1ä¸ªè¯æ®
- è®¾1ä¸ªæœ€å°è¡ŒåŠ¨
6) çº¢æ——ï¼šæš‚æ— æ˜æ˜¾çº¢æ——ï¼Œä½†è‹¥æŒç»­å½±å“ç”Ÿæ´»å»ºè®®æ±‚åŠ©ä¸“ä¸šäººå£«ã€‚
7) ä½ æ¥ä¸‹æ¥å¯èƒ½ä¼šé—®
Qï¼šæˆ‘æ˜¯ä¸æ˜¯å¤ªç»ç’ƒå¿ƒï¼ŸAï¼šçœ‹æ˜¯å¦é•¿æœŸæ¶ˆè€—ä¸åŠŸèƒ½å—å½±å“ã€‚
Qï¼šæ€ä¹ˆé™ä½æ ‡å‡†ï¼ŸAï¼šæŠŠæ ‡å‡†æ‹†æˆâ€œå¿…é¡»/å¯é€‰/åŠ åˆ†â€ã€‚""",
    },
]


def load_icl_file(path: str) -> List[Dict[str, str]]:
    if not path:
        return []
    path = str(path).strip()
    if not path:
        return []
    if not os.path.exists(path):
        raise FileNotFoundError(f"ICL file not found: {path}")

    out: List[Dict[str, str]] = []
    if path.lower().endswith(".json"):
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
        if isinstance(data, list):
            for x in data:
                if not isinstance(x, dict):
                    continue
                u = (x.get("user") or "").strip()
                a = (x.get("assistant") or "").strip()
                if u and a:
                    out.append({"user": u, "assistant": a})
        return out

    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            line = (line or "").strip()
            if not line:
                continue
            x = json.loads(line)
            if not isinstance(x, dict):
                continue
            u = (x.get("user") or "").strip()
            a = (x.get("assistant") or "").strip()
            if u and a:
                out.append({"user": u, "assistant": a})
    return out


def pick_icl(examples: List[Dict[str, str]], k: int, seed: int = 3407) -> List[Dict[str, str]]:
    if not examples or k <= 0:
        return []
    import random
    rng = random.Random(seed)
    idxs = list(range(len(examples)))
    rng.shuffle(idxs)
    picked: List[Dict[str, str]] = []
    for i in idxs:
        ex = examples[i]
        u = (ex.get("user") or "").strip()
        a = (ex.get("assistant") or "").strip()
        if not u or not a:
            continue
        picked.append({"user": u, "assistant": a})
        if len(picked) >= k:
            break
    return picked


def make_messages(user_text: str, icl_examples: Optional[List[Dict[str, str]]], style_injection: str) -> List[Dict[str, str]]:
    style_injection = (style_injection or "both").lower().strip()
    if style_injection not in {"system", "shots", "both"}:
        style_injection = "both"

    sys = REPORT_SPEC + "\n\nï¼ˆä½ å°†çœ‹åˆ°è‹¥å¹² ICL/é£æ ¼ç¤ºä¾‹ï¼šä»…ç”¨äºå­¦ä¹ è¯­æ°”/èŠ‚å¥/æ’ç‰ˆï¼›ä¸å¾—é€å­—ç…§æŠ„ï¼›ä¸å¾—æŠŠç¤ºä¾‹å†…å®¹å½“ä½œäº‹å®ã€‚ï¼‰"
    msgs: List[Dict[str, str]] = [{"role": "system", "content": sys}]

    def _demo_user(i: int, u: str) -> str:
        return f"ã€ç¤ºä¾‹ {i}ã€‘\n{u}\n\nè¯·æŒ‰ REPORT_SPEC çš„ç»“æ„è¾“å‡ºç»“æœã€‚ä¸è¦è§£é‡Šè§„åˆ™ã€‚"

    if icl_examples:
        if style_injection in {"shots", "both"}:
            for i, ex in enumerate(icl_examples, 1):
                u = _basic_safety_sanitize(ex.get("user", ""), max_chars=500)
                a = _basic_safety_sanitize(ex.get("assistant", ""), max_chars=900)
                msgs.append({"role": "user", "content": _demo_user(i, u)})
                msgs.append({"role": "assistant", "content": "ï¼ˆé£æ ¼ç¤ºä¾‹ï¼‰\n" + a})

        if style_injection in {"system", "both"}:
            appendix_lines = []
            for i, ex in enumerate(icl_examples, 1):
                u = _basic_safety_sanitize(ex.get("user", ""), max_chars=220)
                a = _basic_safety_sanitize(ex.get("assistant", ""), max_chars=420)
                appendix_lines.append(f"ä¾‹{i} ç”¨æˆ·ï¼š{u}\nä¾‹{i} åŠ©æ‰‹ï¼š{a}")
            msgs[0]["content"] += "\n\nã€ICL ç¤ºä¾‹ï¼ˆåªå­¦ç»“æ„/è¯­æ°”ï¼›ä¸å¾—ç…§æŠ„ï¼‰ã€‘\n" + "\n\n".join(appendix_lines)

    msgs.append({"role": "user", "content": (user_text or "").strip()})
    return msgs


# -------------------- Model loading --------------------
def load_model_tokenizer(base_model: str, cache_dir: Optional[str], use_unsloth: bool, dtype: str, max_seq_length: int):
    torch_dtype = {
        "bf16": torch.bfloat16,
        "bfloat16": torch.bfloat16,
        "fp16": torch.float16,
        "float16": torch.float16,
    }.get((dtype or "bf16").lower(), torch.bfloat16)

    if use_unsloth:
        from unsloth import FastLanguageModel
        model, tokenizer = FastLanguageModel.from_pretrained(
            model_name=base_model,
            max_seq_length=max_seq_length,
            dtype=torch_dtype,
            load_in_4bit=False,
            cache_dir=cache_dir,
        )
        FastLanguageModel.for_inference(model)
        return model, tokenizer

    from transformers import AutoTokenizer, AutoModelForCausalLM
    tokenizer = AutoTokenizer.from_pretrained(base_model, cache_dir=cache_dir, trust_remote_code=True)
    model = AutoModelForCausalLM.from_pretrained(
        base_model,
        cache_dir=cache_dir,
        torch_dtype=torch_dtype,
        device_map="auto",
        trust_remote_code=True,
    )
    model.eval()
    return model, tokenizer


@torch.inference_mode()
def generate_one(model, tokenizer, messages: List[Dict[str, str]], temperature: float, max_new_tokens: int) -> str:
    if hasattr(tokenizer, "apply_chat_template"):
        prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
        inputs = tokenizer([prompt], return_tensors="pt")
    else:
        prompt = "\n".join([f"{m['role'].upper()}: {m['content']}" for m in messages]) + "\nASSISTANT:"
        inputs = tokenizer([prompt], return_tensors="pt")

    inputs = {k: v.to(model.device) for k, v in inputs.items()}

    gen = model.generate(
        **inputs,
        max_new_tokens=int(max_new_tokens),
        temperature=float(temperature),
        do_sample=(float(temperature) > 0),
        top_p=0.9,
        use_cache=True,
        pad_token_id=getattr(tokenizer, "pad_token_id", None) or getattr(tokenizer, "eos_token_id", None),
        eos_token_id=getattr(tokenizer, "eos_token_id", None),
    )

    out = gen[0]
    n_in = inputs["input_ids"].shape[1]
    text = tokenizer.decode(out[n_in:], skip_special_tokens=True)
    return text.strip()


# -------------------- Gradio App --------------------
def build_app(model, tokenizer, icl_examples: List[Dict[str, str]], style_injection: str, save_dir: str, save_md: bool, base_model_name: str, session_id: str):
    try:
        theme = gr.themes.Soft()
    except Exception:
        theme = None

    save_dir = (save_dir or "").strip()
    save_jsonl_path = None
    save_md_dir = None
    _save_lock = threading.Lock()
    if save_dir:
        os.makedirs(save_dir, exist_ok=True)
        save_jsonl_path = os.path.join(save_dir, "deepsupport_ui_pairs.jsonl")
        if save_md:
            save_md_dir = os.path.join(save_dir, "md")
            os.makedirs(save_md_dir, exist_ok=True)

    def _append_jsonl(obj: Dict[str, Any]) -> None:
        if not save_jsonl_path:
            return
        try:
            line = json.dumps(obj, ensure_ascii=False)
            with _save_lock:
                with open(save_jsonl_path, "a", encoding="utf-8") as f:
                    f.write(line + "\n")
                    f.flush()
        except Exception as e:
            print(f"[WARN] failed to write jsonl: {e}")

    def _write_md(obj: Dict[str, Any], out_text: str) -> None:
        if not save_md_dir:
            return
        try:
            ts = obj.get("time", _now_iso()).replace(":", "").replace("-", "")
            uid = obj.get("uuid", str(uuid.uuid4()))[:8]
            p = os.path.join(save_md_dir, f"{ts}_{uid}.md")
            body = []
            body.append("# DeepSupport Coach Test Log\n")
            body.append(f"- time: {obj.get('time','')}\n- session_id: {obj.get('session_id','')}\n- base_model: {obj.get('base_model','')}\n")
            body.append("\n## Input\n")
            body.append(str(obj.get("input", "")))
            body.append("\n\n## Output\n")
            body.append(out_text)
            with open(p, "w", encoding="utf-8") as f:
                f.write("\n".join(body))
        except Exception as e:
            print(f"[WARN] failed to write md: {e}")

    with gr.Blocks(title="DeepSupport Coach (OSS)", css=MACARON_CSS, theme=theme) as demo:
        gr.HTML(HEADER_HTML)
        with gr.Row(elem_classes=["ds-shell"]):
            with gr.Column(scale=1, elem_classes=["ds-card","ds-card-left"]):
                user_text = gr.Textbox(
                    label="ğŸ’­ ä½ ç°åœ¨æœ€å›°æ‰°çš„ä¸€ä»¶äº‹æ˜¯ä»€ä¹ˆï¼Ÿ",
                    lines=8,
                    placeholder="ç›´æ¥å†™å°±è¡Œï¼Œä¸ç”¨ç»„ç»‡å¾—å¾ˆå®Œç¾ï½",
                    elem_id="ds_user",
                )

                gr.Markdown("#### ğŸŒˆ ä½ å¯èƒ½æƒ³è¯´ ğŸ’¬", elem_classes=["ds-tip"])
                gr.Examples(
                    examples=[
                        ["æˆ‘ä»Šå¤©æ±‡æŠ¥è¢«é¢†å¯¼éª‚äº†ï¼Œæ„Ÿè§‰å¾ˆéš¾å—ï¼Œè„‘å­åœä¸ä¸‹æ¥ã€‚"],
                        ["æˆ‘æœ€è¿‘æ€»æ˜¯å†…è€—å’Œè‡ªæˆ‘å¦å®šï¼Œæ˜æ˜æ²¡å‘ç”Ÿå¤§äº‹ä½†å°±æ˜¯ç´¯ã€‚"],
                        ["æˆ‘è·Ÿå¯¹è±¡åµæ¶äº†ï¼Œä¸€ç›´å¡åœ¨åŒä¸€ä¸ªé—®é¢˜ä¸Šï¼Œä¸çŸ¥é“æ€ä¹ˆæ²Ÿé€šã€‚"],
                    ],
                    inputs=[user_text],
                    label="",
                )

                gr.HTML("<div class=\"ds-flex-spacer\"></div>")
                btn = gr.Button("âœ¨ ç”ŸæˆæŠ¥å‘Š", variant="primary", elem_id="ds_btn")
                btn_new = gr.Button("ğŸ†• æ–°å¯¹è¯", variant="primary", elem_id="ds_btn_new")

            with gr.Column(scale=1, elem_classes=["ds-card"]):
                gr.Markdown("### ğŸ“ è¾“å‡º", elem_classes=["ds-out-title"])
                out_md = gr.Markdown(elem_id="ds_out")

        def _run(_user_text: str):
            ut = (_user_text or "").strip()
            if not ut:
                return "è¯·å…ˆè¾“å…¥ä¸€å¥è¯æè¿°ï¼šä½ ç°åœ¨æœ€å›°æ‰°çš„ä¸€ä»¶äº‹æ˜¯ä»€ä¹ˆï¼Ÿ"

            msgs = make_messages(ut, icl_examples=icl_examples, style_injection=style_injection)
            out = generate_one(model, tokenizer, msgs, temperature=float(DEFAULT_TEMP), max_new_tokens=int(DEFAULT_MAX_NEW_TOKENS))
            out = decorate_output(out)

            rec = {
                "time": _now_iso(),
                "uuid": str(uuid.uuid4()),
                "session_id": session_id,
                "base_model": base_model_name,
                "temperature": float(DEFAULT_TEMP),
                "max_new_tokens": int(DEFAULT_MAX_NEW_TOKENS),
                "style_injection": str(style_injection),
                "num_icl": int(len(icl_examples)) if icl_examples else 0,
                "input": ut,
                "output": out,
            }
            _append_jsonl(rec)
            _write_md(rec, out)
            return out

        def _new_chat():
            return "", ""

        btn.click(_run, inputs=[user_text], outputs=[out_md])
        btn_new.click(_new_chat, inputs=None, outputs=[user_text, out_md])

    return demo


def build_parser():
    p = argparse.ArgumentParser()
    p.add_argument("--base_model", type=str, required=True, help="HF model id or local path (bf16 recommended).")
    p.add_argument("--cache_dir", type=str, default=None, help="HF cache dir.")
    p.add_argument("--host", type=str, default="127.0.0.1")
    p.add_argument("--port", type=int, default=7860, help="Use 0 for auto.")
    p.add_argument("--share", action="store_true", default=False)

    p.add_argument("--use_unsloth", type=lambda x: str(x).lower() in {"1", "true", "yes"}, default=True)
    p.add_argument("--dtype", type=str, default="bf16", choices=["bf16", "bfloat16", "fp16", "float16"])
    p.add_argument("--max_seq_length", type=int, default=4096)

    p.add_argument("--icl_file", type=str, default="", help="JSON/JSONL list of {'user','assistant'} ICL examples (must be sanitized).")
    p.add_argument("--num_icl", type=int, default=2, help="How many ICL examples to inject (0 disables).")
    p.add_argument("--seed", type=int, default=3407)
    p.add_argument("--style_injection", type=str, default="both", choices=["system", "shots", "both"])

    p.add_argument("--save_dir", type=str, default="", help="Directory to save input/output logs (JSONL). Empty disables.")
    p.add_argument("--save_md", action="store_true", help="Also save each interaction as .md under save_dir/md")
    p.add_argument("--session_id", type=str, default="", help="Optional session id for grouping logs")
    return p


def main():
    args = build_parser().parse_args()
    os.environ.setdefault("TOKENIZERS_PARALLELISM", "false")
    if args.cache_dir:
        os.makedirs(args.cache_dir, exist_ok=True)

    icl_pool = list(SYNTHETIC_ICL)
    if args.icl_file and str(args.icl_file).strip():
        ext = load_icl_file(args.icl_file)
        print(f"[ICL] loaded external examples: {len(ext)} from {args.icl_file}")
        icl_pool.extend(ext)

    icl_examples = pick_icl(icl_pool, k=int(args.num_icl), seed=int(args.seed)) if int(args.num_icl) > 0 else []
    print(f"[ICL] pool={len(icl_pool)} picked={len(icl_examples)}")

    print(f"Loading model: {args.base_model}")
    model, tokenizer = load_model_tokenizer(
        base_model=args.base_model,
        cache_dir=args.cache_dir,
        use_unsloth=bool(args.use_unsloth),
        dtype=args.dtype,
        max_seq_length=int(args.max_seq_length),
    )

    base_model_name = str(args.base_model)
    session_id = args.session_id or datetime.datetime.now().strftime("%Y%m%d_%H%M%S") + f"_pid{os.getpid()}"

    app = build_app(
        model,
        tokenizer,
        icl_examples=icl_examples,
        style_injection=str(args.style_injection),
        save_dir=str(args.save_dir),
        save_md=bool(args.save_md),
        base_model_name=base_model_name,
        session_id=session_id,
    )

    port = _pick_free_port(int(args.port), host=args.host)
    if port != int(args.port):
        print(f"[Port] {args.port} is busy. Using free port {port} instead.")
    app.launch(server_name=args.host, server_port=port, share=bool(args.share))


if __name__ == "__main__":
    main()



